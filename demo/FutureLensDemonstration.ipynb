{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12f85d21-cca4-45fc-a878-3266dd72d904",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/KoyenaPal/future-lens/blob/main/demo/FutureLensDemonstration.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" align=\"left\"/></a>&nbsp;or in a local notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d22c79e2-2757-4e60-bb22-75411828da9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "!(stat -t /usr/local/lib/*/dist-packages/google/colab > /dev/null 2>&1) && exit\n",
    "cd /content && rm -rf /content/future-lens\n",
    "git clone https://github.com/KoyenaPal/future-lens future-lens > install.log 2>&1\n",
    "pip install --upgrade google-cloud-storage >> install.log 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f70c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/davidbau/baukit\n",
    "!pip install nnsight==0.5.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c095bf44-8b80-4296-8e74-fa9633abb8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "IS_COLAB = False\n",
    "try:\n",
    "    import google.colab, torch, os\n",
    "    IS_COLAB = True\n",
    "    os.chdir(\"/content/future-lens/demo\")\n",
    "    if not torch.cuda.is_available():\n",
    "        raise Exception(\"Change runtime type to include a GPU.\")\n",
    "except ModuleNotFoundError as _:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fda1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnsight import CONFIG\n",
    "from IPython.display import clear_output\n",
    "\n",
    "if IS_COLAB:\n",
    "    # include your NNsight API key on Colab secrets\n",
    "    from google.colab import userdata\n",
    "    NDIF_API = userdata.get('NDIF_API')\n",
    "    CONFIG.set_default_api_key(NDIF_API)\n",
    "elif not CONFIG.API.APIKEY:\n",
    "    CONFIG.API.APIKEY = input(\"Enter your API key: \")\n",
    "    clear_output()\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8056dba8-e1d2-4bef-bb34-3d954fa77b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-10-24 13:54:37--  https://baulab.us/u/koyena/data/future-lens/gptj_soft_prefix.pt\n",
      "Resolving baulab.us (baulab.us)... 129.10.121.189\n",
      "Connecting to baulab.us (baulab.us)|129.10.121.189|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 82743 (81K)\n",
      "Saving to: ‘gptj_soft_prefix.pt’\n",
      "\n",
      "gptj_soft_prefix.pt 100%[===================>]  80.80K  --.-KB/s    in 0.002s  \n",
      "\n",
      "2025-10-24 13:54:37 (44.4 MB/s) - ‘gptj_soft_prefix.pt’ saved [82743/82743]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nnsight import LanguageModel\n",
    "from lens import load_prefix, show_future_lens\n",
    "import lens\n",
    "import cloudpickle\n",
    "cloudpickle.register_pickle_by_value(lens)\n",
    "import torch\n",
    "!wget https://baulab.us/u/koyena/data/future-lens/gptj_soft_prefix.pt -O gptj_soft_prefix.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df107e78-a762-4175-92f4-9b703876fa11",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'EleutherAI/gpt-j-6b'\n",
    "PREFIX_PATH = \"gptj_soft_prefix.pt\"\n",
    "DEVICE = \"auto\"\n",
    "\n",
    "#torch_dtype=torch.bfloat16,\n",
    "model = LanguageModel(MODEL_NAME, device_map=DEVICE, low_cpu_mem_usage=True)\n",
    "learned_context = load_prefix(PREFIX_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab96838-e6d2-4e8c-bc58-053e77d86827",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-10-24 13:54:38] [46f51c72-ab05-4826-acf9-2018f10769fb] RECEIVED   : Your job has been received and is waiting to be queued.\n",
      "[2025-10-24 13:54:38] [46f51c72-ab05-4826-acf9-2018f10769fb] QUEUED     : Your job has been recieved by the coordinator and is waiting to be queued.\n",
      "[2025-10-24 13:54:38] [46f51c72-ab05-4826-acf9-2018f10769fb] QUEUED     : Task 46f51c72-ab05-4826-acf9-2018f10769fb has been added to the queue. Currently at position 1\n",
      "[2025-10-24 13:54:39] [46f51c72-ab05-4826-acf9-2018f10769fb] DISPATCHED : Dispatching task...\n",
      "[2025-10-24 13:54:39] [46f51c72-ab05-4826-acf9-2018f10769fb] RUNNING    : Your job has started running.\n",
      "[2025-10-24 13:54:40] [46f51c72-ab05-4826-acf9-2018f10769fb] COMPLETED  : Your job has been completed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8e0f385a09241cbb4e904ca39f8203b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading result:   0%|          | 0.00/15.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-10-24 13:54:47] [500d136c-f871-48e2-9295-bad6c9cc1c62] RECEIVED   : Your job has been received and is waiting to be queued.\n",
      "[2025-10-24 13:54:47] [500d136c-f871-48e2-9295-bad6c9cc1c62] QUEUED     : Your job has been recieved by the coordinator and is waiting to be queued.\n",
      "[2025-10-24 13:54:47] [500d136c-f871-48e2-9295-bad6c9cc1c62] QUEUED     : Task 500d136c-f871-48e2-9295-bad6c9cc1c62 has been added to the queue. Currently at position 1\n",
      "[2025-10-24 13:54:47] [500d136c-f871-48e2-9295-bad6c9cc1c62] DISPATCHED : Dispatching task...\n",
      "[2025-10-24 13:54:48] [500d136c-f871-48e2-9295-bad6c9cc1c62] RUNNING    : Your job has started running.\n"
     ]
    },
    {
     "ename": "RemoteException",
     "evalue": "Traceback (most recent call last):\n  File \"/u/svcndifuser/ndif-deployment/repos/prod/ndif/src/services/ray/src/ray/deployments/modeling/base.py\", line 206, in __call__\n    result = await job_task\n             ^^^^^^^^^^^^^^\n  File \"/u/svcndifuser/miniconda3/envs/service/lib/python3.12/asyncio/threads.py\", line 25, in to_thread\n    return await loop.run_in_executor(None, func_call)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/u/svcndifuser/miniconda3/envs/service/lib/python3.12/concurrent/futures/thread.py\", line 59, in run\n    result = self.fn(*self.args, **self.kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/u/svcndifuser/miniconda3/envs/service/lib/python3.12/site-packages/ray/util/tracing/tracing_helper.py\", line 463, in _resume_span\n    return method(self, *_args, **_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/u/svcndifuser/ndif-deployment/repos/prod/ndif/src/services/ray/src/ray/deployments/modeling/base.py\", line 273, in execute\n    result = RemoteExecutionBackend(request.interventions, self.execution_protector)(request.tracer)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/u/svcndifuser/ndif-deployment/repos/prod/ndif/src/services/ray/src/ray/nn/backend.py\", line 27, in __call__\n    run(tracer, self.fn)\n  File \"/u/svcndifuser/ndif-deployment/repos/prod/ndif/src/services/ray/src/ray/nn/sandbox.py\", line 16, in run\n    raise wrap_exception(e,tracer.info) from None\nnnsight.NNsightException: \n\nTraceback (most recent call last):\n  File \"/u/svcndifuser/ndif-deployment/repos/prod/ndif/src/services/ray/src/ray/nn/sandbox.py\", line 14, in run\n    tracer.execute(fn)\n  File \"/u/svcndifuser/miniconda3/envs/service/lib/python3.12/site-packages/nnsight/intervention/tracing/base.py\", line 424, in execute\n    fn(self, self.info)\n  File \"/u/svcndifuser/ndif-deployment/repos/prod/ndif/src/services/ray/src/ray/nn/sandbox.py\", line 14, in run\n    with model.generate(max_new_tokens=num_toks_gen, pad_token_id=50256, remote=remote) as generator:\n  File \"/u/svcndifuser/miniconda3/envs/service/lib/python3.12/site-packages/nnsight/intervention/envoy.py\", line 1031, in trace\n    return self.trace(*args, fn=value, **kwargs)\n  File \"/u/svcndifuser/miniconda3/envs/service/lib/python3.12/site-packages/nnsight/modeling/mixins/remoteable.py\", line 30, in trace\n    backend = RemoteBackend(self.to_model_key(), blocking=blocking)\n  File \"/u/svcndifuser/miniconda3/envs/service/lib/python3.12/site-packages/nnsight/modeling/mixins/remoteable.py\", line 80, in to_model_key\n    return f\"{import_path}:{self._remoteable_model_key()}\"\n  File \"/u/svcndifuser/miniconda3/envs/service/lib/python3.12/site-packages/nnsight/modeling/language.py\", line 395, in _remoteable_model_key\n    repo_id = HfApi().model_info(self.repo_id).id\n  File \"/u/svcndifuser/miniconda3/envs/service/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n    return fn(*args, **kwargs)\n  File \"/u/svcndifuser/miniconda3/envs/service/lib/python3.12/site-packages/huggingface_hub/hf_api.py\", line 2640, in model_info\n    return ModelInfo(**data)\n  File \"/u/svcndifuser/miniconda3/envs/service/lib/python3.12/site-packages/huggingface_hub/hf_api.py\", line 856, in __init__\n    self.last_modified = parse_datetime(last_modified) if last_modified else None\n  File \"/u/svcndifuser/miniconda3/envs/service/lib/python3.12/site-packages/huggingface_hub/utils/_datetime.py\", line 62, in parse_datetime\n    return datetime.strptime(date_string, \"%Y-%m-%dT%H:%M:%S.%fZ\").replace(tzinfo=timezone.utc)\n  File \"/u/svcndifuser/ndif-deployment/repos/prod/ndif/src/services/ray/src/ray/nn/security/protected_environment.py\", line 172, in __call__\n    raise ImportError(f\"Module {name} is not whitelisted\")\n\nImportError: Module _strptime is not whitelisted\n\n\n\nTraceback (most recent call last):\n  File \"/u/svcndifuser/ndif-deployment/repos/prod/ndif/src/services/ray/src/ray/nn/sandbox.py\", line 14, in run\n    tracer.execute(fn)\n  File \"/u/svcndifuser/miniconda3/envs/service/lib/python3.12/site-packages/nnsight/intervention/tracing/base.py\", line 424, in execute\n    fn(self, self.info)\n  File \"/u/svcndifuser/ndif-deployment/repos/prod/ndif/src/services/ray/src/ray/nn/sandbox.py\", line 14, in run\n    with model.generate(max_new_tokens=num_toks_gen, pad_token_id=50256, remote=remote) as generator:\n  File \"/u/svcndifuser/miniconda3/envs/service/lib/python3.12/site-packages/nnsight/intervention/envoy.py\", line 1031, in trace\n    return self.trace(*args, fn=value, **kwargs)\n  File \"/u/svcndifuser/miniconda3/envs/service/lib/python3.12/site-packages/nnsight/modeling/mixins/remoteable.py\", line 30, in trace\n    backend = RemoteBackend(self.to_model_key(), blocking=blocking)\n  File \"/u/svcndifuser/miniconda3/envs/service/lib/python3.12/site-packages/nnsight/modeling/mixins/remoteable.py\", line 80, in to_model_key\n    return f\"{import_path}:{self._remoteable_model_key()}\"\n  File \"/u/svcndifuser/miniconda3/envs/service/lib/python3.12/site-packages/nnsight/modeling/language.py\", line 395, in _remoteable_model_key\n    repo_id = HfApi().model_info(self.repo_id).id\n  File \"/u/svcndifuser/miniconda3/envs/service/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n    return fn(*args, **kwargs)\n  File \"/u/svcndifuser/miniconda3/envs/service/lib/python3.12/site-packages/huggingface_hub/hf_api.py\", line 2640, in model_info\n    return ModelInfo(**data)\n  File \"/u/svcndifuser/miniconda3/envs/service/lib/python3.12/site-packages/huggingface_hub/hf_api.py\", line 856, in __init__\n    self.last_modified = parse_datetime(last_modified) if last_modified else None\n  File \"/u/svcndifuser/miniconda3/envs/service/lib/python3.12/site-packages/huggingface_hub/utils/_datetime.py\", line 62, in parse_datetime\n    return datetime.strptime(date_string, \"%Y-%m-%dT%H:%M:%S.%fZ\").replace(tzinfo=timezone.utc)\n  File \"/u/svcndifuser/ndif-deployment/repos/prod/ndif/src/services/ray/src/ray/nn/security/protected_environment.py\", line 172, in __call__\n    raise ImportError(f\"Module {name} is not whitelisted\")\n\nImportError: Module _strptime is not whitelisted\nRemote exception.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mExitTracingException\u001b[39m                      Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/future-lens/demo/lens.py:39\u001b[39m, in \u001b[36mshow_future_lens\u001b[39m\u001b[34m(model, tok, prefix, context, in_layer, tgt_in_layer, topk, num_toks_gen, context_pos, color, remote)\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m model.session(remote=remote):\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     counter = \u001b[32;43m0\u001b[39;49m\n\u001b[32m     40\u001b[39m     future_outputs = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/newmats/lib/python3.12/site-packages/nnsight/intervention/tracing/base.py:564\u001b[39m, in \u001b[36mTracer.__enter__.<locals>.skip_traced_code\u001b[39m\u001b[34m(frame, event, arg)\u001b[39m\n\u001b[32m    563\u001b[39m \u001b[38;5;66;03m# Raise exception to exit normal execution flow\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m564\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m ExitTracingException()\n",
      "\u001b[31mExitTracingException\u001b[39m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mRemoteException\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Note: This may take a while to run since it is loading the model before displaying the future lens.\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Also note: In Google Colab, you are most likely going to require Google Colab Pro\u001b[39;00m\n\u001b[32m      4\u001b[39m user_input = \u001b[33m\"\u001b[39m\u001b[33mMarty McFly from\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43mshow_future_lens\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlearned_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremote\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/future-lens/demo/lens.py:38\u001b[39m, in \u001b[36mshow_future_lens\u001b[39m\u001b[34m(model, tok, prefix, context, in_layer, tgt_in_layer, topk, num_toks_gen, context_pos, color, remote)\u001b[39m\n\u001b[32m     36\u001b[39m hs = [curr_hs \u001b[38;5;28;01mfor\u001b[39;00m curr_hs \u001b[38;5;129;01min\u001b[39;00m overall_hs]\n\u001b[32m     37\u001b[39m first_set_logits = torch.stack(first_set_logits)\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43msession\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremote\u001b[49m\u001b[43m=\u001b[49m\u001b[43mremote\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcounter\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\n\u001b[32m     40\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfuture_outputs\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/newmats/lib/python3.12/site-packages/nnsight/intervention/tracing/base.py:599\u001b[39m, in \u001b[36mTracer.__exit__\u001b[39m\u001b[34m(self, exc_type, exc_val, exc_tb)\u001b[39m\n\u001b[32m    595\u001b[39m \u001b[38;5;66;03m# Handle the ExitTracingException (our control flow mechanism)\u001b[39;00m\n\u001b[32m    596\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m exc_type \u001b[38;5;129;01mis\u001b[39;00m ExitTracingException:\n\u001b[32m    597\u001b[39m     \u001b[38;5;66;03m# This is the expected case - the traced code was intercepted\u001b[39;00m\n\u001b[32m    598\u001b[39m     \u001b[38;5;66;03m# Execute the captured code using the configured backend\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m599\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    601\u001b[39m     \u001b[38;5;66;03m# Return True to suppress the ExitTracingException\u001b[39;00m\n\u001b[32m    602\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/newmats/lib/python3.12/site-packages/nnsight/intervention/backends/remote.py:90\u001b[39m, in \u001b[36mRemoteBackend.__call__\u001b[39m\u001b[34m(self, tracer)\u001b[39m\n\u001b[32m     85\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, tracer = \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m     87\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.blocking:\n\u001b[32m     88\u001b[39m \n\u001b[32m     89\u001b[39m         \u001b[38;5;66;03m# Do blocking request.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m         result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mblocking_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtracer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     92\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     93\u001b[39m \n\u001b[32m     94\u001b[39m         \u001b[38;5;66;03m# Otherwise we are getting the status / result of the existing job.\u001b[39;00m\n\u001b[32m     95\u001b[39m         result = \u001b[38;5;28mself\u001b[39m.non_blocking_request(tracer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/newmats/lib/python3.12/site-packages/nnsight/intervention/backends/remote.py:302\u001b[39m, in \u001b[36mRemoteBackend.blocking_request\u001b[39m\u001b[34m(self, tracer)\u001b[39m\n\u001b[32m    298\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[32m    300\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m302\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    304\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    305\u001b[39m     LocalTracer.deregister()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/newmats/lib/python3.12/site-packages/nnsight/intervention/backends/remote.py:295\u001b[39m, in \u001b[36mRemoteBackend.blocking_request\u001b[39m\u001b[34m(self, tracer)\u001b[39m\n\u001b[32m    293\u001b[39m response = ResponseModel.unpickle(response)\n\u001b[32m    294\u001b[39m \u001b[38;5;66;03m# Handle the response.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m295\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandle_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtracer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[38;5;66;03m# Break when completed.\u001b[39;00m\n\u001b[32m    297\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/newmats/lib/python3.12/site-packages/nnsight/intervention/backends/remote.py:125\u001b[39m, in \u001b[36mRemoteBackend.handle_response\u001b[39m\u001b[34m(self, response, tracer)\u001b[39m\n\u001b[32m    122\u001b[39m \u001b[38;5;28mself\u001b[39m.job_status = response.status\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response.status == ResponseModel.JobStatus.ERROR:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m RemoteException(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.description\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mRemote exception.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    127\u001b[39m \u001b[38;5;66;03m# Log response for user\u001b[39;00m\n\u001b[32m    128\u001b[39m response.log(remote_logger)\n",
      "\u001b[31mRemoteException\u001b[39m: Traceback (most recent call last):\n  File \"/u/svcndifuser/ndif-deployment/repos/prod/ndif/src/services/ray/src/ray/deployments/modeling/base.py\", line 206, in __call__\n    result = await job_task\n             ^^^^^^^^^^^^^^\n  File \"/u/svcndifuser/miniconda3/envs/service/lib/python3.12/asyncio/threads.py\", line 25, in to_thread\n    return await loop.run_in_executor(None, func_call)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/u/svcndifuser/miniconda3/envs/service/lib/python3.12/concurrent/futures/thread.py\", line 59, in run\n    result = self.fn(*self.args, **self.kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/u/svcndifuser/miniconda3/envs/service/lib/python3.12/site-packages/ray/util/tracing/tracing_helper.py\", line 463, in _resume_span\n    return method(self, *_args, **_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/u/svcndifuser/ndif-deployment/repos/prod/ndif/src/services/ray/src/ray/deployments/modeling/base.py\", line 273, in execute\n    result = RemoteExecutionBackend(request.interventions, self.execution_protector)(request.tracer)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/u/svcndifuser/ndif-deployment/repos/prod/ndif/src/services/ray/src/ray/nn/backend.py\", line 27, in __call__\n    run(tracer, self.fn)\n  File \"/u/svcndifuser/ndif-deployment/repos/prod/ndif/src/services/ray/src/ray/nn/sandbox.py\", line 16, in run\n    raise wrap_exception(e,tracer.info) from None\nnnsight.NNsightException: \n\nTraceback (most recent call last):\n  File \"/u/svcndifuser/ndif-deployment/repos/prod/ndif/src/services/ray/src/ray/nn/sandbox.py\", line 14, in run\n    tracer.execute(fn)\n  File \"/u/svcndifuser/miniconda3/envs/service/lib/python3.12/site-packages/nnsight/intervention/tracing/base.py\", line 424, in execute\n    fn(self, self.info)\n  File \"/u/svcndifuser/ndif-deployment/repos/prod/ndif/src/services/ray/src/ray/nn/sandbox.py\", line 14, in run\n    with model.generate(max_new_tokens=num_toks_gen, pad_token_id=50256, remote=remote) as generator:\n  File \"/u/svcndifuser/miniconda3/envs/service/lib/python3.12/site-packages/nnsight/intervention/envoy.py\", line 1031, in trace\n    return self.trace(*args, fn=value, **kwargs)\n  File \"/u/svcndifuser/miniconda3/envs/service/lib/python3.12/site-packages/nnsight/modeling/mixins/remoteable.py\", line 30, in trace\n    backend = RemoteBackend(self.to_model_key(), blocking=blocking)\n  File \"/u/svcndifuser/miniconda3/envs/service/lib/python3.12/site-packages/nnsight/modeling/mixins/remoteable.py\", line 80, in to_model_key\n    return f\"{import_path}:{self._remoteable_model_key()}\"\n  File \"/u/svcndifuser/miniconda3/envs/service/lib/python3.12/site-packages/nnsight/modeling/language.py\", line 395, in _remoteable_model_key\n    repo_id = HfApi().model_info(self.repo_id).id\n  File \"/u/svcndifuser/miniconda3/envs/service/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n    return fn(*args, **kwargs)\n  File \"/u/svcndifuser/miniconda3/envs/service/lib/python3.12/site-packages/huggingface_hub/hf_api.py\", line 2640, in model_info\n    return ModelInfo(**data)\n  File \"/u/svcndifuser/miniconda3/envs/service/lib/python3.12/site-packages/huggingface_hub/hf_api.py\", line 856, in __init__\n    self.last_modified = parse_datetime(last_modified) if last_modified else None\n  File \"/u/svcndifuser/miniconda3/envs/service/lib/python3.12/site-packages/huggingface_hub/utils/_datetime.py\", line 62, in parse_datetime\n    return datetime.strptime(date_string, \"%Y-%m-%dT%H:%M:%S.%fZ\").replace(tzinfo=timezone.utc)\n  File \"/u/svcndifuser/ndif-deployment/repos/prod/ndif/src/services/ray/src/ray/nn/security/protected_environment.py\", line 172, in __call__\n    raise ImportError(f\"Module {name} is not whitelisted\")\n\nImportError: Module _strptime is not whitelisted\n\n\n\nTraceback (most recent call last):\n  File \"/u/svcndifuser/ndif-deployment/repos/prod/ndif/src/services/ray/src/ray/nn/sandbox.py\", line 14, in run\n    tracer.execute(fn)\n  File \"/u/svcndifuser/miniconda3/envs/service/lib/python3.12/site-packages/nnsight/intervention/tracing/base.py\", line 424, in execute\n    fn(self, self.info)\n  File \"/u/svcndifuser/ndif-deployment/repos/prod/ndif/src/services/ray/src/ray/nn/sandbox.py\", line 14, in run\n    with model.generate(max_new_tokens=num_toks_gen, pad_token_id=50256, remote=remote) as generator:\n  File \"/u/svcndifuser/miniconda3/envs/service/lib/python3.12/site-packages/nnsight/intervention/envoy.py\", line 1031, in trace\n    return self.trace(*args, fn=value, **kwargs)\n  File \"/u/svcndifuser/miniconda3/envs/service/lib/python3.12/site-packages/nnsight/modeling/mixins/remoteable.py\", line 30, in trace\n    backend = RemoteBackend(self.to_model_key(), blocking=blocking)\n  File \"/u/svcndifuser/miniconda3/envs/service/lib/python3.12/site-packages/nnsight/modeling/mixins/remoteable.py\", line 80, in to_model_key\n    return f\"{import_path}:{self._remoteable_model_key()}\"\n  File \"/u/svcndifuser/miniconda3/envs/service/lib/python3.12/site-packages/nnsight/modeling/language.py\", line 395, in _remoteable_model_key\n    repo_id = HfApi().model_info(self.repo_id).id\n  File \"/u/svcndifuser/miniconda3/envs/service/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n    return fn(*args, **kwargs)\n  File \"/u/svcndifuser/miniconda3/envs/service/lib/python3.12/site-packages/huggingface_hub/hf_api.py\", line 2640, in model_info\n    return ModelInfo(**data)\n  File \"/u/svcndifuser/miniconda3/envs/service/lib/python3.12/site-packages/huggingface_hub/hf_api.py\", line 856, in __init__\n    self.last_modified = parse_datetime(last_modified) if last_modified else None\n  File \"/u/svcndifuser/miniconda3/envs/service/lib/python3.12/site-packages/huggingface_hub/utils/_datetime.py\", line 62, in parse_datetime\n    return datetime.strptime(date_string, \"%Y-%m-%dT%H:%M:%S.%fZ\").replace(tzinfo=timezone.utc)\n  File \"/u/svcndifuser/ndif-deployment/repos/prod/ndif/src/services/ray/src/ray/nn/security/protected_environment.py\", line 172, in __call__\n    raise ImportError(f\"Module {name} is not whitelisted\")\n\nImportError: Module _strptime is not whitelisted\nRemote exception."
     ]
    }
   ],
   "source": [
    "# Note: This may take a while to run since it is loading the model before displaying the future lens.\n",
    "# Also note: In Google Colab, you are most likely going to require Google Colab Pro\n",
    "\n",
    "user_input = \"Marty McFly from\"\n",
    "show_future_lens(model, model.tokenizer, prefix=user_input, context=learned_context, remote=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newmats",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
